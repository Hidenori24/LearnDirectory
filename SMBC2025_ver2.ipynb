{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvg/5t3KIE9fJOT3N8zgZH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hidenori24/LearnDirectory/blob/master/SMBC2025_ver2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. ライブラリセットアップ\n"
      ],
      "metadata": {
        "id": "5idmRN9YE8EI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0ZWUiAp_EmOg"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 0. ライブラリ & CFG 定義\n",
        "# ============================================\n",
        "!pip -q install lightgbm==4.3.0 polars==0.20.19 holidays==0.42\n",
        "!pip install -U scikit-learn -q\n",
        "\n",
        "import os, random, math, gc, pickle, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import lightgbm as lgb\n",
        "import holidays\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ---------- CFG ----------\n",
        "class CFG:\n",
        "    seed         = 42\n",
        "    n_folds      = 5\n",
        "    early_stop   = 300\n",
        "    num_boost_round = 20_000\n",
        "    test_size_hr = 4380          # ≒6ヶ月\n",
        "    lags         = [1, 24]\n",
        "    rolls        = [24, 168]\n",
        "    data_path    = '/content/drive/MyDrive/ML/Signate_1634/'\n",
        "    use_polars   = False         # True にすると FE 後が高速\n",
        "    lgb_params = {\n",
        "        'objective'      : 'regression',\n",
        "        'metric'         : 'rmse',\n",
        "        'learning_rate'  : 0.05,\n",
        "        'num_leaves'     : 256,\n",
        "        'subsample'      : 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'seed'           : seed,\n",
        "        'verbose'        : -1,\n",
        "    }\n",
        "\n",
        "# set seed\n",
        "random.seed(CFG.seed)\n",
        "np.random.seed(CFG.seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Google Drive マウント\n"
      ],
      "metadata": {
        "id": "fMaGVka5FB7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 1. Google Drive マウント\n",
        "# ============================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG6UMAE3Eqdv",
        "outputId": "7dbdc51b-8532-4a35-d203-d2237340f37f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. データ読み込み"
      ],
      "metadata": {
        "id": "guK8i2niFK0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2. データ読み込み\n",
        "#    - index を DatetimeIndex（UTC）に\n",
        "# =========================================================\n",
        "def read_data(path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)                 # まずは普通に読み込み\n",
        "    df['time'] = pd.to_datetime(df['time'], utc=True)   # ①文字列→datetime(UTC)\n",
        "    df['time'] = df['time'].dt.tz_convert(None)         # ②タイムゾーン情報を外す（naive へ）\n",
        "    df = df.set_index('time').sort_index()              # ③DatetimeIndex として設定\n",
        "    return df\n",
        "\n",
        "train_df = read_data(os.path.join(CFG.data_path, 'train.csv'))\n",
        "test_df  = read_data(os.path.join(CFG.data_path, 'test.csv'))\n",
        "\n",
        "print('train', train_df.shape, 'test', test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJKz_c6jEsq1",
        "outputId": "8ad06542-842a-4cc7-86ab-0b7e1026c427"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train (26280, 91) test (8760, 90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 特徴量生成"
      ],
      "metadata": {
        "id": "dTc-JyB1FMV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 3. 特徴量エンジニアリング (改善版)\n",
        "# ============================================\n",
        "es_holidays = holidays.country_holidays('ES', years=range(2015, 2019))\n",
        "holiday_set = set(es_holidays.keys())  # set で高速判定\n",
        "\n",
        "def add_calendar(df):\n",
        "    idx = df.index\n",
        "    df['hour']       = idx.hour\n",
        "    df['dow']        = idx.dayofweek\n",
        "    df['month']      = idx.month\n",
        "    df['is_weekend'] = (df['dow'] >= 5).astype(np.int8)\n",
        "    df['is_holiday'] = np.isin(idx.date, list(holiday_set)).astype(np.int8)\n",
        "\n",
        "    df['sin_hour'] = np.sin(2*np.pi*df['hour']/24)\n",
        "    df['cos_hour'] = np.cos(2*np.pi*df['hour']/24)\n",
        "    df['sin_dow']  = np.sin(2*np.pi*df['dow']/7)\n",
        "    df['cos_dow']  = np.cos(2*np.pi*df['dow']/7)\n",
        "    df['sin_month'] = np.sin(2*np.pi*(df['month']-1)/12) # 月の周期性\n",
        "    df['cos_month'] = np.cos(2*np.pi*(df['month']-1)/12)\n",
        "\n",
        "    return df\n",
        "\n",
        "def add_supply_gap(df):\n",
        "    gen_cols = [c for c in df.columns if c.startswith('generation_')]\n",
        "    df['supply_total'] = df[gen_cols].sum(axis=1)\n",
        "    df['gap_supply_demand'] = df['supply_total'] - df['total_load_actual']\n",
        "\n",
        "    ren_cols = [c for c in gen_cols if any(k in c for k in ['solar','wind','hydro'])]\n",
        "    df['renewable_ratio'] = df[ren_cols].sum(axis=1) / df['supply_total']\n",
        "    df['renewable_ratio'] = df['renewable_ratio'].replace([np.inf, -np.inf], np.nan).fillna(0) # 無限大やNaNの処理\n",
        "    return df\n",
        "\n",
        "# 改善1: より多くのラグとロールを追加\n",
        "def add_lag_roll_enhanced(df, lags=None, rolls=None):\n",
        "    if lags is None:\n",
        "        lags = [1, 24, 24*7, 24*30] # 1時間、1日、1週間、1ヶ月のラグを追加\n",
        "    if rolls is None:\n",
        "        rolls = [24, 168, 24*30] # 1日、1週間、1ヶ月のロールを追加\n",
        "\n",
        "    for l in lags:\n",
        "        df[f'price_lag_{l}']  = df['price_actual'].shift(l)\n",
        "        df[f'demand_lag_{l}'] = df['total_load_actual'].shift(l)\n",
        "    for r in rolls:\n",
        "        df[f'price_rollmean_{r}'] = df['price_actual'].shift(1).rolling(r).mean()\n",
        "        df[f'price_rollstd_{r}'] = df['price_actual'].shift(1).rolling(r).std() # priceにもrollstdを追加\n",
        "        df[f'gap_rollstd_{r}']    = df['gap_supply_demand'].shift(1).rolling(r).std()\n",
        "        df[f'demand_rollmean_{r}'] = df['total_load_actual'].shift(1).rolling(r).mean() # demandにもrollmeanを追加\n",
        "    return df\n",
        "\n",
        "# 改善2: 時間に関連する交互作用特徴量\n",
        "def add_interaction_features(df):\n",
        "    df['hour_x_dow'] = df['hour'] * df['dow']\n",
        "    df['is_weekend_x_hour'] = df['is_weekend'] * df['hour']\n",
        "    df['is_holiday_x_hour'] = df['is_holiday'] * df['hour']\n",
        "    return df\n",
        "\n",
        "def make_features_enhanced(full):\n",
        "    full = add_calendar(full)\n",
        "    full = add_supply_gap(full)\n",
        "    full = add_lag_roll_enhanced(full) # 改善1の関数を呼び出し\n",
        "    full = add_interaction_features(full) # 改善2の関数を呼び出し\n",
        "    return full\n",
        "\n",
        "# train+test を縦結合して一括 FE\n",
        "full_df = pd.concat(\n",
        "    [train_df, test_df.assign(price_actual=np.nan)],\n",
        "    axis=0\n",
        ")\n",
        "full_df = make_features_enhanced(full_df) # 改善版の特徴量生成関数を使用\n",
        "\n",
        "# 欠損補完（時系列なので forward → 数値列平均）\n",
        "full_df = full_df.fillna(method='ffill')\n",
        "num_cols = full_df.select_dtypes(include=[np.number, 'bool']).columns\n",
        "full_df[num_cols] = full_df[num_cols].fillna(full_df[num_cols].mean())\n",
        "\n",
        "print('FE 完了:', full_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNTw5dRGEuCe",
        "outputId": "93d161fe-3290-4975-bb4f-01db489d4caa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE 完了: (35040, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 数値列 & カテゴリー列を分離"
      ],
      "metadata": {
        "id": "PfqCv0ijFOM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 4. 数値列 & カテゴリー列を分離\n",
        "#    ─ LightGBM にカテゴリーを渡す設定 ─\n",
        "# ============================================\n",
        "TARGET = 'price_actual'\n",
        "\n",
        "# 1) すべての object 列を category 型へ変換\n",
        "str_cols = full_df.select_dtypes('object').columns\n",
        "full_df[str_cols] = full_df[str_cols].astype('category')\n",
        "\n",
        "# 2) カテゴリー列リストを自動取得\n",
        "cat_cols = list(full_df.select_dtypes('category').columns)\n",
        "\n",
        "# LightGBM 用のカテゴリー列名リスト\n",
        "lgb_cat_features = cat_cols\n",
        "\n",
        "# XGBoost は、通常は数値特徴量として扱うか、One-Hot Encoding などの前処理が必要です。\n",
        "# ここではシンプルに数値変換された特徴量をそのまま渡すため、特別な設定は不要です。\n",
        "\n",
        "# 3) 特徴量リスト（目的変数を除く全列）\n",
        "features = [c for c in full_df.columns if c != TARGET]\n",
        "\n",
        "# 4) 学習・テスト DataFrame\n",
        "train_fe = full_df.loc[train_df.index]\n",
        "test_fe  = full_df.loc[test_df.index]\n",
        "\n",
        "# 5) 学習 / 推論データ\n",
        "# XGBoost は pandas DataFrame をそのまま扱えるため、LightGBM の to_numeric_np はここでは不要ですが、\n",
        "# LightGBM のために残しておきます。\n",
        "X_train, y_train = train_fe[features], train_fe[TARGET]\n",
        "X_test           = test_fe[features]\n",
        "\n",
        "# カテゴリー列を数値に変換 (XGBoost も内部で処理できますが、明示的に変換しておくことも可能です)\n",
        "# ここでは LightGBM の to_numeric_np 関数を再利用します。\n",
        "def to_numeric_np(df: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    - category は codes(int32)\n",
        "    - object が残っていれば factorize(int32)\n",
        "    - 数値 / bool はそのまま\n",
        "    \"\"\"\n",
        "    df_num = df.copy()\n",
        "\n",
        "    # category → int32\n",
        "    for col in cat_cols:\n",
        "        df_num[col] = df_num[col].cat.codes.astype('int32')\n",
        "\n",
        "    # 念のため残っている object 列を factorize\n",
        "    obj_cols = df_num.select_dtypes('object').columns\n",
        "    for col in obj_cols:\n",
        "        df_num[col] = pd.factorize(df_num[col], sort=True)[0].astype('int32')\n",
        "\n",
        "    return df_num.to_numpy(dtype=np.float32)"
      ],
      "metadata": {
        "id": "KIQ-glPpEweF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 時系列 CV & LightGBM 学習"
      ],
      "metadata": {
        "id": "Kgev0x-kFPg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 5. LightGBM / XGBoost 時系列 CV 学習\n",
        "# =========================================================\n",
        "!pip install xgboost==2.0.3 -q # XGBoost をインストール\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=CFG.n_folds, test_size=CFG.test_size_hr)\n",
        "oof_lgb = np.zeros(len(X_train))\n",
        "pred_lgb = np.zeros(len(X_test))\n",
        "oof_xgb = np.zeros(len(X_train))\n",
        "pred_xgb = np.zeros(len(X_test))\n",
        "\n",
        "# XGBoost のパラメータ例\n",
        "# LightGBM とは異なるパラメータ名と値になることが多いです。\n",
        "xgb_params = {\n",
        "    'objective': 'reg:squarederror', # 回帰問題の目的関数\n",
        "    'eval_metric': 'rmse',           # 評価指標\n",
        "    'eta': 0.05,                      # 学習率\n",
        "    'max_depth': 8,                   # 木の最大深度\n",
        "    'subsample': 0.8,                 # 各木を構築する際のデータのサンプリング率\n",
        "    'colsample_bytree': 0.8,          # 各木を構築する際の列のサンプリング率\n",
        "    'seed': CFG.seed,\n",
        "    'nthread': -1,                    # 使用するスレッド数 (-1で全スレッド)\n",
        "    'tree_method': 'hist',            # 大規模データ向きの高速なツリー構築アルゴリズム\n",
        "    'disable_default_eval_metric': 1  # デフォルトの評価指標を使わない\n",
        "}\n",
        "\n",
        "for fold, (tr_idx, val_idx) in enumerate(tscv.split(X_train)):\n",
        "    print(f'\\n---- Fold {fold} ----')\n",
        "    X_tr, y_tr = X_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
        "    X_val, y_val = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    # LightGBM の学習\n",
        "    print('  Training LightGBM...')\n",
        "    lgb_train = lgb.Dataset(X_tr, label=y_tr, categorical_feature=lgb_cat_features, free_raw_data=False)\n",
        "    lgb_val   = lgb.Dataset(X_val, label=y_val, categorical_feature=lgb_cat_features, free_raw_data=False)\n",
        "\n",
        "    model_lgb = lgb.train(\n",
        "        CFG.lgb_params,\n",
        "        lgb_train,\n",
        "        num_boost_round=CFG.num_boost_round,\n",
        "        valid_sets=[lgb_train, lgb_val],\n",
        "        valid_names=['train','valid'],\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(CFG.early_stop, verbose=True),\n",
        "            lgb.log_evaluation(500)\n",
        "        ]\n",
        "    )\n",
        "    # LightGBM OOF\n",
        "    oof_lgb[val_idx] = model_lgb.predict(\n",
        "        to_numeric_np(X_val),\n",
        "        num_iteration=model_lgb.best_iteration\n",
        "    )\n",
        "\n",
        "    # LightGBM TEST\n",
        "    pred_lgb += model_lgb.predict(\n",
        "        to_numeric_np(X_test),\n",
        "        num_iteration=model_lgb.best_iteration\n",
        "    ) / CFG.n_folds\n",
        "\n",
        "    # XGBoost の学習\n",
        "    print('  Training XGBoost...')\n",
        "    # XGBoost は DMatrix 形式に変換するのが一般的ですが、DataFrame も扱えます。\n",
        "    # ここでは簡単のため DataFrame のまま渡します。\n",
        "    # カテゴリー特徴量は、通常は数値に変換済みである必要があります。\n",
        "    model_xgb = xgb.XGBRegressor(**xgb_params)\n",
        "\n",
        "    model_xgb.fit(\n",
        "        # 修正点: XGBoost に渡すデータを数値に変換\n",
        "        to_numeric_np(X_tr), y_tr,\n",
        "        eval_set=[(to_numeric_np(X_val), y_val)], # 修正点: eval_set のデータも数値に変換\n",
        "        early_stopping_rounds=CFG.early_stop,\n",
        "        verbose=True # ここでは log_evaluation の代わりに verbose を使用\n",
        "    )\n",
        "\n",
        "    # XGBoost OOF\n",
        "    oof_xgb[val_idx] = model_xgb.predict(to_numeric_np(X_val))\n",
        "\n",
        "    # XGBoost TEST\n",
        "    pred_xgb += model_xgb.predict(to_numeric_np(X_test)) / CFG.n_folds\n",
        "\n",
        "\n",
        "# モデルごとの OOF RMSE を計算\n",
        "rmse_lgb = np.sqrt(mean_squared_error(y_train, oof_lgb))\n",
        "print(f'\\nLightGBM OOF RMSE = {rmse_lgb:.4f}')\n",
        "\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_train, oof_xgb))\n",
        "print(f'XGBoost OOF RMSE = {rmse_xgb:.4f}')\n",
        "\n",
        "# 複数モデルの予測を組み合わせる例 (平均)\n",
        "# oof_combined = (oof_lgb + oof_xgb) / 2\n",
        "# pred_combined = (pred_lgb + pred_xgb) / 2\n",
        "# rmse_combined = np.sqrt(mean_squared_error(y_train, oof_combined))\n",
        "# print(f'Combined OOF RMSE (Average) = {rmse_combined:.4f}')\n",
        "\n",
        "# 提出には、性能の良い方のモデル、または組み合わせたモデルの予測を使用します。\n",
        "# ここでは、例として LightGBM の予測を使用します。\n",
        "final_pred = pred_lgb\n",
        "final_oof = oof_lgb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJWMv2JEx8O",
        "outputId": "2198c5e7-4d21-494d-8b20-49e48ea62b8e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---- Fold 0 ----\n",
            "  Training LightGBM...\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "Early stopping, best iteration is:\n",
            "[106]\ttrain's rmse: 0.946248\tvalid's rmse: 2.76023\n",
            "  Training XGBoost...\n",
            "[0]\tvalidation_0-rmse:10.89218\n",
            "[1]\tvalidation_0-rmse:10.40095\n",
            "[2]\tvalidation_0-rmse:9.94333\n",
            "[3]\tvalidation_0-rmse:9.62205\n",
            "[4]\tvalidation_0-rmse:9.21176\n",
            "[5]\tvalidation_0-rmse:8.82370\n",
            "[6]\tvalidation_0-rmse:8.44663\n",
            "[7]\tvalidation_0-rmse:8.09366\n",
            "[8]\tvalidation_0-rmse:7.77449\n",
            "[9]\tvalidation_0-rmse:7.45800\n",
            "[10]\tvalidation_0-rmse:7.17376\n",
            "[11]\tvalidation_0-rmse:6.89717\n",
            "[12]\tvalidation_0-rmse:6.62802\n",
            "[13]\tvalidation_0-rmse:6.37152\n",
            "[14]\tvalidation_0-rmse:6.19019\n",
            "[15]\tvalidation_0-rmse:6.05146\n",
            "[16]\tvalidation_0-rmse:5.83775\n",
            "[17]\tvalidation_0-rmse:5.63792\n",
            "[18]\tvalidation_0-rmse:5.45871\n",
            "[19]\tvalidation_0-rmse:5.31029\n",
            "[20]\tvalidation_0-rmse:5.15027\n",
            "[21]\tvalidation_0-rmse:4.99448\n",
            "[22]\tvalidation_0-rmse:4.85149\n",
            "[23]\tvalidation_0-rmse:4.74758\n",
            "[24]\tvalidation_0-rmse:4.61993\n",
            "[25]\tvalidation_0-rmse:4.50375\n",
            "[26]\tvalidation_0-rmse:4.38662\n",
            "[27]\tvalidation_0-rmse:4.27733\n",
            "[28]\tvalidation_0-rmse:4.17966\n",
            "[29]\tvalidation_0-rmse:4.09423\n",
            "[30]\tvalidation_0-rmse:4.01208\n",
            "[31]\tvalidation_0-rmse:3.92619\n",
            "[32]\tvalidation_0-rmse:3.84905\n",
            "[33]\tvalidation_0-rmse:3.77714\n",
            "[34]\tvalidation_0-rmse:3.71228\n",
            "[35]\tvalidation_0-rmse:3.64933\n",
            "[36]\tvalidation_0-rmse:3.59619\n",
            "[37]\tvalidation_0-rmse:3.54483\n",
            "[38]\tvalidation_0-rmse:3.51905\n",
            "[39]\tvalidation_0-rmse:3.48391\n",
            "[40]\tvalidation_0-rmse:3.43540\n",
            "[41]\tvalidation_0-rmse:3.39232\n",
            "[42]\tvalidation_0-rmse:3.35495\n",
            "[43]\tvalidation_0-rmse:3.32436\n",
            "[44]\tvalidation_0-rmse:3.28867\n",
            "[45]\tvalidation_0-rmse:3.25464\n",
            "[46]\tvalidation_0-rmse:3.22429\n",
            "[47]\tvalidation_0-rmse:3.20459\n",
            "[48]\tvalidation_0-rmse:3.17928\n",
            "[49]\tvalidation_0-rmse:3.15898\n",
            "[50]\tvalidation_0-rmse:3.14317\n",
            "[51]\tvalidation_0-rmse:3.12939\n",
            "[52]\tvalidation_0-rmse:3.12109\n",
            "[53]\tvalidation_0-rmse:3.10444\n",
            "[54]\tvalidation_0-rmse:3.08775\n",
            "[55]\tvalidation_0-rmse:3.07312\n",
            "[56]\tvalidation_0-rmse:3.05852\n",
            "[57]\tvalidation_0-rmse:3.04908\n",
            "[58]\tvalidation_0-rmse:3.03758\n",
            "[59]\tvalidation_0-rmse:3.02624\n",
            "[60]\tvalidation_0-rmse:3.01518\n",
            "[61]\tvalidation_0-rmse:3.00690\n",
            "[62]\tvalidation_0-rmse:2.99673\n",
            "[63]\tvalidation_0-rmse:2.98665\n",
            "[64]\tvalidation_0-rmse:2.97901\n",
            "[65]\tvalidation_0-rmse:2.97128\n",
            "[66]\tvalidation_0-rmse:2.96245\n",
            "[67]\tvalidation_0-rmse:2.95399\n",
            "[68]\tvalidation_0-rmse:2.94785\n",
            "[69]\tvalidation_0-rmse:2.94169\n",
            "[70]\tvalidation_0-rmse:2.93874\n",
            "[71]\tvalidation_0-rmse:2.93468\n",
            "[72]\tvalidation_0-rmse:2.93042\n",
            "[73]\tvalidation_0-rmse:2.92685\n",
            "[74]\tvalidation_0-rmse:2.92231\n",
            "[75]\tvalidation_0-rmse:2.91848\n",
            "[76]\tvalidation_0-rmse:2.91363\n",
            "[77]\tvalidation_0-rmse:2.91018\n",
            "[78]\tvalidation_0-rmse:2.90629\n",
            "[79]\tvalidation_0-rmse:2.90353\n",
            "[80]\tvalidation_0-rmse:2.90122\n",
            "[81]\tvalidation_0-rmse:2.89811\n",
            "[82]\tvalidation_0-rmse:2.89572\n",
            "[83]\tvalidation_0-rmse:2.89064\n",
            "[84]\tvalidation_0-rmse:2.88844\n",
            "[85]\tvalidation_0-rmse:2.88617\n",
            "[86]\tvalidation_0-rmse:2.88317\n",
            "[87]\tvalidation_0-rmse:2.88033\n",
            "[88]\tvalidation_0-rmse:2.87942\n",
            "[89]\tvalidation_0-rmse:2.87854\n",
            "[90]\tvalidation_0-rmse:2.87778\n",
            "[91]\tvalidation_0-rmse:2.87696\n",
            "[92]\tvalidation_0-rmse:2.87538\n",
            "[93]\tvalidation_0-rmse:2.87488\n",
            "[94]\tvalidation_0-rmse:2.87312\n",
            "[95]\tvalidation_0-rmse:2.87084\n",
            "[96]\tvalidation_0-rmse:2.87023\n",
            "[97]\tvalidation_0-rmse:2.86930\n",
            "[98]\tvalidation_0-rmse:2.86869\n",
            "[99]\tvalidation_0-rmse:2.86704\n",
            "\n",
            "---- Fold 1 ----\n",
            "  Training LightGBM...\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "Early stopping, best iteration is:\n",
            "[123]\ttrain's rmse: 0.755909\tvalid's rmse: 4.21702\n",
            "  Training XGBoost...\n",
            "[0]\tvalidation_0-rmse:24.16502\n",
            "[1]\tvalidation_0-rmse:23.08260\n",
            "[2]\tvalidation_0-rmse:22.05397\n",
            "[3]\tvalidation_0-rmse:21.44001\n",
            "[4]\tvalidation_0-rmse:20.58105\n",
            "[5]\tvalidation_0-rmse:19.68449\n",
            "[6]\tvalidation_0-rmse:18.95676\n",
            "[7]\tvalidation_0-rmse:18.18869\n",
            "[8]\tvalidation_0-rmse:17.45572\n",
            "[9]\tvalidation_0-rmse:16.72392\n",
            "[10]\tvalidation_0-rmse:16.12201\n",
            "[11]\tvalidation_0-rmse:15.55805\n",
            "[12]\tvalidation_0-rmse:15.02404\n",
            "[13]\tvalidation_0-rmse:14.48254\n",
            "[14]\tvalidation_0-rmse:14.11580\n",
            "[15]\tvalidation_0-rmse:13.96778\n",
            "[16]\tvalidation_0-rmse:13.51818\n",
            "[17]\tvalidation_0-rmse:13.06365\n",
            "[18]\tvalidation_0-rmse:12.62630\n",
            "[19]\tvalidation_0-rmse:12.40916\n",
            "[20]\tvalidation_0-rmse:12.03123\n",
            "[21]\tvalidation_0-rmse:11.67479\n",
            "[22]\tvalidation_0-rmse:11.34589\n",
            "[23]\tvalidation_0-rmse:11.15638\n",
            "[24]\tvalidation_0-rmse:10.84467\n",
            "[25]\tvalidation_0-rmse:10.55209\n",
            "[26]\tvalidation_0-rmse:10.27717\n",
            "[27]\tvalidation_0-rmse:10.00910\n",
            "[28]\tvalidation_0-rmse:9.81093\n",
            "[29]\tvalidation_0-rmse:9.58603\n",
            "[30]\tvalidation_0-rmse:9.38658\n",
            "[31]\tvalidation_0-rmse:9.19871\n",
            "[32]\tvalidation_0-rmse:8.99498\n",
            "[33]\tvalidation_0-rmse:8.82245\n",
            "[34]\tvalidation_0-rmse:8.66552\n",
            "[35]\tvalidation_0-rmse:8.50126\n",
            "[36]\tvalidation_0-rmse:8.33888\n",
            "[37]\tvalidation_0-rmse:8.19562\n",
            "[38]\tvalidation_0-rmse:8.09465\n",
            "[39]\tvalidation_0-rmse:8.01193\n",
            "[40]\tvalidation_0-rmse:7.88011\n",
            "[41]\tvalidation_0-rmse:7.76764\n",
            "[42]\tvalidation_0-rmse:7.63882\n",
            "[43]\tvalidation_0-rmse:7.53263\n",
            "[44]\tvalidation_0-rmse:7.42387\n",
            "[45]\tvalidation_0-rmse:7.32139\n",
            "[46]\tvalidation_0-rmse:7.20651\n",
            "[47]\tvalidation_0-rmse:7.13504\n",
            "[48]\tvalidation_0-rmse:7.04552\n",
            "[49]\tvalidation_0-rmse:6.97416\n",
            "[50]\tvalidation_0-rmse:6.91600\n",
            "[51]\tvalidation_0-rmse:6.87105\n",
            "[52]\tvalidation_0-rmse:6.85474\n",
            "[53]\tvalidation_0-rmse:6.77928\n",
            "[54]\tvalidation_0-rmse:6.69258\n",
            "[55]\tvalidation_0-rmse:6.62726\n",
            "[56]\tvalidation_0-rmse:6.56776\n",
            "[57]\tvalidation_0-rmse:6.52598\n",
            "[58]\tvalidation_0-rmse:6.47801\n",
            "[59]\tvalidation_0-rmse:6.46548\n",
            "[60]\tvalidation_0-rmse:6.41855\n",
            "[61]\tvalidation_0-rmse:6.37665\n",
            "[62]\tvalidation_0-rmse:6.33245\n",
            "[63]\tvalidation_0-rmse:6.28043\n",
            "[64]\tvalidation_0-rmse:6.23240\n",
            "[65]\tvalidation_0-rmse:6.19581\n",
            "[66]\tvalidation_0-rmse:6.15897\n",
            "[67]\tvalidation_0-rmse:6.12388\n",
            "[68]\tvalidation_0-rmse:6.08969\n",
            "[69]\tvalidation_0-rmse:6.05967\n",
            "[70]\tvalidation_0-rmse:6.05467\n",
            "[71]\tvalidation_0-rmse:6.03926\n",
            "[72]\tvalidation_0-rmse:6.02367\n",
            "[73]\tvalidation_0-rmse:6.00827\n",
            "[74]\tvalidation_0-rmse:5.98168\n",
            "[75]\tvalidation_0-rmse:5.96091\n",
            "[76]\tvalidation_0-rmse:5.94600\n",
            "[77]\tvalidation_0-rmse:5.93074\n",
            "[78]\tvalidation_0-rmse:5.92037\n",
            "[79]\tvalidation_0-rmse:5.91341\n",
            "[80]\tvalidation_0-rmse:5.89777\n",
            "[81]\tvalidation_0-rmse:5.88775\n",
            "[82]\tvalidation_0-rmse:5.86672\n",
            "[83]\tvalidation_0-rmse:5.84522\n",
            "[84]\tvalidation_0-rmse:5.82663\n",
            "[85]\tvalidation_0-rmse:5.81912\n",
            "[86]\tvalidation_0-rmse:5.81483\n",
            "[87]\tvalidation_0-rmse:5.80246\n",
            "[88]\tvalidation_0-rmse:5.80119\n",
            "[89]\tvalidation_0-rmse:5.79906\n",
            "[90]\tvalidation_0-rmse:5.79443\n",
            "[91]\tvalidation_0-rmse:5.77907\n",
            "[92]\tvalidation_0-rmse:5.77121\n",
            "[93]\tvalidation_0-rmse:5.76186\n",
            "[94]\tvalidation_0-rmse:5.74720\n",
            "[95]\tvalidation_0-rmse:5.73683\n",
            "[96]\tvalidation_0-rmse:5.73584\n",
            "[97]\tvalidation_0-rmse:5.72579\n",
            "[98]\tvalidation_0-rmse:5.72194\n",
            "[99]\tvalidation_0-rmse:5.71245\n",
            "\n",
            "---- Fold 2 ----\n",
            "  Training LightGBM...\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "Early stopping, best iteration is:\n",
            "[180]\ttrain's rmse: 0.613823\tvalid's rmse: 2.09741\n",
            "  Training XGBoost...\n",
            "[0]\tvalidation_0-rmse:10.60466\n",
            "[1]\tvalidation_0-rmse:10.12843\n",
            "[2]\tvalidation_0-rmse:9.65627\n",
            "[3]\tvalidation_0-rmse:9.28603\n",
            "[4]\tvalidation_0-rmse:8.85504\n",
            "[5]\tvalidation_0-rmse:8.45627\n",
            "[6]\tvalidation_0-rmse:8.07265\n",
            "[7]\tvalidation_0-rmse:7.71439\n",
            "[8]\tvalidation_0-rmse:7.36769\n",
            "[9]\tvalidation_0-rmse:7.03646\n",
            "[10]\tvalidation_0-rmse:6.73762\n",
            "[11]\tvalidation_0-rmse:6.43605\n",
            "[12]\tvalidation_0-rmse:6.15793\n",
            "[13]\tvalidation_0-rmse:5.90174\n",
            "[14]\tvalidation_0-rmse:5.69767\n",
            "[15]\tvalidation_0-rmse:5.51201\n",
            "[16]\tvalidation_0-rmse:5.29214\n",
            "[17]\tvalidation_0-rmse:5.07931\n",
            "[18]\tvalidation_0-rmse:4.87864\n",
            "[19]\tvalidation_0-rmse:4.71501\n",
            "[20]\tvalidation_0-rmse:4.55102\n",
            "[21]\tvalidation_0-rmse:4.39870\n",
            "[22]\tvalidation_0-rmse:4.24233\n",
            "[23]\tvalidation_0-rmse:4.12924\n",
            "[24]\tvalidation_0-rmse:3.99499\n",
            "[25]\tvalidation_0-rmse:3.86333\n",
            "[26]\tvalidation_0-rmse:3.73481\n",
            "[27]\tvalidation_0-rmse:3.62293\n",
            "[28]\tvalidation_0-rmse:3.52034\n",
            "[29]\tvalidation_0-rmse:3.42654\n",
            "[30]\tvalidation_0-rmse:3.33829\n",
            "[31]\tvalidation_0-rmse:3.24854\n",
            "[32]\tvalidation_0-rmse:3.17986\n",
            "[33]\tvalidation_0-rmse:3.10415\n",
            "[34]\tvalidation_0-rmse:3.03192\n",
            "[35]\tvalidation_0-rmse:2.96550\n",
            "[36]\tvalidation_0-rmse:2.90757\n",
            "[37]\tvalidation_0-rmse:2.85203\n",
            "[38]\tvalidation_0-rmse:2.80827\n",
            "[39]\tvalidation_0-rmse:2.75930\n",
            "[40]\tvalidation_0-rmse:2.71074\n",
            "[41]\tvalidation_0-rmse:2.66675\n",
            "[42]\tvalidation_0-rmse:2.63056\n",
            "[43]\tvalidation_0-rmse:2.59235\n",
            "[44]\tvalidation_0-rmse:2.55318\n",
            "[45]\tvalidation_0-rmse:2.51990\n",
            "[46]\tvalidation_0-rmse:2.49265\n",
            "[47]\tvalidation_0-rmse:2.46763\n",
            "[48]\tvalidation_0-rmse:2.44311\n",
            "[49]\tvalidation_0-rmse:2.42135\n",
            "[50]\tvalidation_0-rmse:2.40414\n",
            "[51]\tvalidation_0-rmse:2.38994\n",
            "[52]\tvalidation_0-rmse:2.37683\n",
            "[53]\tvalidation_0-rmse:2.35632\n",
            "[54]\tvalidation_0-rmse:2.33854\n",
            "[55]\tvalidation_0-rmse:2.32628\n",
            "[56]\tvalidation_0-rmse:2.31315\n",
            "[57]\tvalidation_0-rmse:2.30236\n",
            "[58]\tvalidation_0-rmse:2.28966\n",
            "[59]\tvalidation_0-rmse:2.27853\n",
            "[60]\tvalidation_0-rmse:2.26939\n",
            "[61]\tvalidation_0-rmse:2.26123\n",
            "[62]\tvalidation_0-rmse:2.25213\n",
            "[63]\tvalidation_0-rmse:2.24364\n",
            "[64]\tvalidation_0-rmse:2.23696\n",
            "[65]\tvalidation_0-rmse:2.22854\n",
            "[66]\tvalidation_0-rmse:2.22059\n",
            "[67]\tvalidation_0-rmse:2.21529\n",
            "[68]\tvalidation_0-rmse:2.20927\n",
            "[69]\tvalidation_0-rmse:2.20329\n",
            "[70]\tvalidation_0-rmse:2.19841\n",
            "[71]\tvalidation_0-rmse:2.19268\n",
            "[72]\tvalidation_0-rmse:2.18819\n",
            "[73]\tvalidation_0-rmse:2.18379\n",
            "[74]\tvalidation_0-rmse:2.18001\n",
            "[75]\tvalidation_0-rmse:2.17669\n",
            "[76]\tvalidation_0-rmse:2.17381\n",
            "[77]\tvalidation_0-rmse:2.17155\n",
            "[78]\tvalidation_0-rmse:2.16696\n",
            "[79]\tvalidation_0-rmse:2.16384\n",
            "[80]\tvalidation_0-rmse:2.15991\n",
            "[81]\tvalidation_0-rmse:2.15746\n",
            "[82]\tvalidation_0-rmse:2.15517\n",
            "[83]\tvalidation_0-rmse:2.15430\n",
            "[84]\tvalidation_0-rmse:2.15172\n",
            "[85]\tvalidation_0-rmse:2.15052\n",
            "[86]\tvalidation_0-rmse:2.14801\n",
            "[87]\tvalidation_0-rmse:2.14601\n",
            "[88]\tvalidation_0-rmse:2.14465\n",
            "[89]\tvalidation_0-rmse:2.13895\n",
            "[90]\tvalidation_0-rmse:2.13761\n",
            "[91]\tvalidation_0-rmse:2.13607\n",
            "[92]\tvalidation_0-rmse:2.13567\n",
            "[93]\tvalidation_0-rmse:2.13419\n",
            "[94]\tvalidation_0-rmse:2.13405\n",
            "[95]\tvalidation_0-rmse:2.13223\n",
            "[96]\tvalidation_0-rmse:2.13190\n",
            "[97]\tvalidation_0-rmse:2.13277\n",
            "[98]\tvalidation_0-rmse:2.13198\n",
            "[99]\tvalidation_0-rmse:2.13109\n",
            "\n",
            "---- Fold 3 ----\n",
            "  Training LightGBM...\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "Early stopping, best iteration is:\n",
            "[151]\ttrain's rmse: 0.851042\tvalid's rmse: 3.43687\n",
            "  Training XGBoost...\n",
            "[0]\tvalidation_0-rmse:13.73859\n",
            "[1]\tvalidation_0-rmse:13.17309\n",
            "[2]\tvalidation_0-rmse:12.65297\n",
            "[3]\tvalidation_0-rmse:12.23097\n",
            "[4]\tvalidation_0-rmse:11.74817\n",
            "[5]\tvalidation_0-rmse:11.26577\n",
            "[6]\tvalidation_0-rmse:10.81941\n",
            "[7]\tvalidation_0-rmse:10.39505\n",
            "[8]\tvalidation_0-rmse:9.98681\n",
            "[9]\tvalidation_0-rmse:9.61587\n",
            "[10]\tvalidation_0-rmse:9.39802\n",
            "[11]\tvalidation_0-rmse:9.08799\n",
            "[12]\tvalidation_0-rmse:8.80549\n",
            "[13]\tvalidation_0-rmse:8.49090\n",
            "[14]\tvalidation_0-rmse:8.26301\n",
            "[15]\tvalidation_0-rmse:8.04802\n",
            "[16]\tvalidation_0-rmse:7.87001\n",
            "[17]\tvalidation_0-rmse:7.64805\n",
            "[18]\tvalidation_0-rmse:7.40880\n",
            "[19]\tvalidation_0-rmse:7.22623\n",
            "[20]\tvalidation_0-rmse:7.03266\n",
            "[21]\tvalidation_0-rmse:6.87730\n",
            "[22]\tvalidation_0-rmse:6.70518\n",
            "[23]\tvalidation_0-rmse:6.56683\n",
            "[24]\tvalidation_0-rmse:6.46243\n",
            "[25]\tvalidation_0-rmse:6.31693\n",
            "[26]\tvalidation_0-rmse:6.17720\n",
            "[27]\tvalidation_0-rmse:6.06381\n",
            "[28]\tvalidation_0-rmse:5.93267\n",
            "[29]\tvalidation_0-rmse:5.81451\n",
            "[30]\tvalidation_0-rmse:5.73286\n",
            "[31]\tvalidation_0-rmse:5.62731\n",
            "[32]\tvalidation_0-rmse:5.53620\n",
            "[33]\tvalidation_0-rmse:5.42936\n",
            "[34]\tvalidation_0-rmse:5.36466\n",
            "[35]\tvalidation_0-rmse:5.29176\n",
            "[36]\tvalidation_0-rmse:5.21217\n",
            "[37]\tvalidation_0-rmse:5.13634\n",
            "[38]\tvalidation_0-rmse:5.07594\n",
            "[39]\tvalidation_0-rmse:5.01866\n",
            "[40]\tvalidation_0-rmse:4.96520\n",
            "[41]\tvalidation_0-rmse:4.91443\n",
            "[42]\tvalidation_0-rmse:4.87070\n",
            "[43]\tvalidation_0-rmse:4.81847\n",
            "[44]\tvalidation_0-rmse:4.74956\n",
            "[45]\tvalidation_0-rmse:4.69676\n",
            "[46]\tvalidation_0-rmse:4.65619\n",
            "[47]\tvalidation_0-rmse:4.62409\n",
            "[48]\tvalidation_0-rmse:4.58541\n",
            "[49]\tvalidation_0-rmse:4.54919\n",
            "[50]\tvalidation_0-rmse:4.51739\n",
            "[51]\tvalidation_0-rmse:4.50003\n",
            "[52]\tvalidation_0-rmse:4.47437\n",
            "[53]\tvalidation_0-rmse:4.45458\n",
            "[54]\tvalidation_0-rmse:4.43108\n",
            "[55]\tvalidation_0-rmse:4.40127\n",
            "[56]\tvalidation_0-rmse:4.37605\n",
            "[57]\tvalidation_0-rmse:4.36079\n",
            "[58]\tvalidation_0-rmse:4.33286\n",
            "[59]\tvalidation_0-rmse:4.32195\n",
            "[60]\tvalidation_0-rmse:4.30291\n",
            "[61]\tvalidation_0-rmse:4.28472\n",
            "[62]\tvalidation_0-rmse:4.26918\n",
            "[63]\tvalidation_0-rmse:4.25627\n",
            "[64]\tvalidation_0-rmse:4.24437\n",
            "[65]\tvalidation_0-rmse:4.22846\n",
            "[66]\tvalidation_0-rmse:4.21595\n",
            "[67]\tvalidation_0-rmse:4.20260\n",
            "[68]\tvalidation_0-rmse:4.18758\n",
            "[69]\tvalidation_0-rmse:4.17581\n",
            "[70]\tvalidation_0-rmse:4.16610\n",
            "[71]\tvalidation_0-rmse:4.15767\n",
            "[72]\tvalidation_0-rmse:4.14427\n",
            "[73]\tvalidation_0-rmse:4.13689\n",
            "[74]\tvalidation_0-rmse:4.12384\n",
            "[75]\tvalidation_0-rmse:4.10975\n",
            "[76]\tvalidation_0-rmse:4.10171\n",
            "[77]\tvalidation_0-rmse:4.09440\n",
            "[78]\tvalidation_0-rmse:4.08551\n",
            "[79]\tvalidation_0-rmse:4.07779\n",
            "[80]\tvalidation_0-rmse:4.07287\n",
            "[81]\tvalidation_0-rmse:4.06670\n",
            "[82]\tvalidation_0-rmse:4.06130\n",
            "[83]\tvalidation_0-rmse:4.05638\n",
            "[84]\tvalidation_0-rmse:4.05084\n",
            "[85]\tvalidation_0-rmse:4.04134\n",
            "[86]\tvalidation_0-rmse:4.03913\n",
            "[87]\tvalidation_0-rmse:4.03628\n",
            "[88]\tvalidation_0-rmse:4.03407\n",
            "[89]\tvalidation_0-rmse:4.03063\n",
            "[90]\tvalidation_0-rmse:4.02757\n",
            "[91]\tvalidation_0-rmse:4.02490\n",
            "[92]\tvalidation_0-rmse:4.02144\n",
            "[93]\tvalidation_0-rmse:4.01829\n",
            "[94]\tvalidation_0-rmse:4.01677\n",
            "[95]\tvalidation_0-rmse:4.01429\n",
            "[96]\tvalidation_0-rmse:4.01140\n",
            "[97]\tvalidation_0-rmse:4.00729\n",
            "[98]\tvalidation_0-rmse:4.00601\n",
            "[99]\tvalidation_0-rmse:4.00607\n",
            "\n",
            "---- Fold 4 ----\n",
            "  Training LightGBM...\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "[500]\ttrain's rmse: 0.264648\tvalid's rmse: 2.33396\n",
            "Early stopping, best iteration is:\n",
            "[218]\ttrain's rmse: 0.711188\tvalid's rmse: 2.32768\n",
            "  Training XGBoost...\n",
            "[0]\tvalidation_0-rmse:11.11032\n",
            "[1]\tvalidation_0-rmse:10.59901\n",
            "[2]\tvalidation_0-rmse:10.10814\n",
            "[3]\tvalidation_0-rmse:9.71699\n",
            "[4]\tvalidation_0-rmse:9.28256\n",
            "[5]\tvalidation_0-rmse:8.86781\n",
            "[6]\tvalidation_0-rmse:8.47618\n",
            "[7]\tvalidation_0-rmse:8.10145\n",
            "[8]\tvalidation_0-rmse:7.75127\n",
            "[9]\tvalidation_0-rmse:7.41998\n",
            "[10]\tvalidation_0-rmse:7.10146\n",
            "[11]\tvalidation_0-rmse:6.80802\n",
            "[12]\tvalidation_0-rmse:6.52957\n",
            "[13]\tvalidation_0-rmse:6.27063\n",
            "[14]\tvalidation_0-rmse:6.05399\n",
            "[15]\tvalidation_0-rmse:5.85703\n",
            "[16]\tvalidation_0-rmse:5.63190\n",
            "[17]\tvalidation_0-rmse:5.41911\n",
            "[18]\tvalidation_0-rmse:5.21964\n",
            "[19]\tvalidation_0-rmse:5.06561\n",
            "[20]\tvalidation_0-rmse:4.89370\n",
            "[21]\tvalidation_0-rmse:4.72995\n",
            "[22]\tvalidation_0-rmse:4.57199\n",
            "[23]\tvalidation_0-rmse:4.45036\n",
            "[24]\tvalidation_0-rmse:4.30982\n",
            "[25]\tvalidation_0-rmse:4.18174\n",
            "[26]\tvalidation_0-rmse:4.06130\n",
            "[27]\tvalidation_0-rmse:3.94568\n",
            "[28]\tvalidation_0-rmse:3.84235\n",
            "[29]\tvalidation_0-rmse:3.74468\n",
            "[30]\tvalidation_0-rmse:3.64964\n",
            "[31]\tvalidation_0-rmse:3.56295\n",
            "[32]\tvalidation_0-rmse:3.48459\n",
            "[33]\tvalidation_0-rmse:3.41022\n",
            "[34]\tvalidation_0-rmse:3.34005\n",
            "[35]\tvalidation_0-rmse:3.27705\n",
            "[36]\tvalidation_0-rmse:3.21635\n",
            "[37]\tvalidation_0-rmse:3.15850\n",
            "[38]\tvalidation_0-rmse:3.11659\n",
            "[39]\tvalidation_0-rmse:3.07307\n",
            "[40]\tvalidation_0-rmse:3.03065\n",
            "[41]\tvalidation_0-rmse:2.98749\n",
            "[42]\tvalidation_0-rmse:2.94409\n",
            "[43]\tvalidation_0-rmse:2.90587\n",
            "[44]\tvalidation_0-rmse:2.87093\n",
            "[45]\tvalidation_0-rmse:2.83833\n",
            "[46]\tvalidation_0-rmse:2.80910\n",
            "[47]\tvalidation_0-rmse:2.78563\n",
            "[48]\tvalidation_0-rmse:2.75849\n",
            "[49]\tvalidation_0-rmse:2.73371\n",
            "[50]\tvalidation_0-rmse:2.71789\n",
            "[51]\tvalidation_0-rmse:2.70164\n",
            "[52]\tvalidation_0-rmse:2.68643\n",
            "[53]\tvalidation_0-rmse:2.66773\n",
            "[54]\tvalidation_0-rmse:2.64973\n",
            "[55]\tvalidation_0-rmse:2.63478\n",
            "[56]\tvalidation_0-rmse:2.61935\n",
            "[57]\tvalidation_0-rmse:2.60865\n",
            "[58]\tvalidation_0-rmse:2.59481\n",
            "[59]\tvalidation_0-rmse:2.58545\n",
            "[60]\tvalidation_0-rmse:2.57314\n",
            "[61]\tvalidation_0-rmse:2.56287\n",
            "[62]\tvalidation_0-rmse:2.55239\n",
            "[63]\tvalidation_0-rmse:2.54317\n",
            "[64]\tvalidation_0-rmse:2.53571\n",
            "[65]\tvalidation_0-rmse:2.52747\n",
            "[66]\tvalidation_0-rmse:2.51920\n",
            "[67]\tvalidation_0-rmse:2.51135\n",
            "[68]\tvalidation_0-rmse:2.50656\n",
            "[69]\tvalidation_0-rmse:2.50074\n",
            "[70]\tvalidation_0-rmse:2.49650\n",
            "[71]\tvalidation_0-rmse:2.49000\n",
            "[72]\tvalidation_0-rmse:2.48596\n",
            "[73]\tvalidation_0-rmse:2.47777\n",
            "[74]\tvalidation_0-rmse:2.47373\n",
            "[75]\tvalidation_0-rmse:2.47002\n",
            "[76]\tvalidation_0-rmse:2.46342\n",
            "[77]\tvalidation_0-rmse:2.46023\n",
            "[78]\tvalidation_0-rmse:2.45525\n",
            "[79]\tvalidation_0-rmse:2.45276\n",
            "[80]\tvalidation_0-rmse:2.44818\n",
            "[81]\tvalidation_0-rmse:2.44654\n",
            "[82]\tvalidation_0-rmse:2.44318\n",
            "[83]\tvalidation_0-rmse:2.44044\n",
            "[84]\tvalidation_0-rmse:2.43819\n",
            "[85]\tvalidation_0-rmse:2.43555\n",
            "[86]\tvalidation_0-rmse:2.43359\n",
            "[87]\tvalidation_0-rmse:2.43073\n",
            "[88]\tvalidation_0-rmse:2.42761\n",
            "[89]\tvalidation_0-rmse:2.42255\n",
            "[90]\tvalidation_0-rmse:2.41974\n",
            "[91]\tvalidation_0-rmse:2.41868\n",
            "[92]\tvalidation_0-rmse:2.41724\n",
            "[93]\tvalidation_0-rmse:2.41560\n",
            "[94]\tvalidation_0-rmse:2.41431\n",
            "[95]\tvalidation_0-rmse:2.41304\n",
            "[96]\tvalidation_0-rmse:2.41173\n",
            "[97]\tvalidation_0-rmse:2.40767\n",
            "[98]\tvalidation_0-rmse:2.40706\n",
            "[99]\tvalidation_0-rmse:2.40415\n",
            "\n",
            "LightGBM OOF RMSE = 25.2349\n",
            "XGBoost OOF RMSE = 25.3008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 提出ファイル生成"
      ],
      "metadata": {
        "id": "qgQ4CfGfFQs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 6. 提出ファイル生成\n",
        "# =========================================================\n",
        "sub = pd.DataFrame({\n",
        "    'time': test_df.index.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'price_actual': final_pred # 最終的に使用する予測\n",
        "})\n",
        "save_path = os.path.join(CFG.data_path, 'submission_enhanced.csv') # ファイル名を変更\n",
        "sub.to_csv(save_path, index=False)\n",
        "print('saved to', save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQYxehpDEz2r",
        "outputId": "ecebe002-20df-486b-8706-21b5d380a1ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved to /content/drive/MyDrive/ML/Signate_1634/submission_enhanced.csv\n"
          ]
        }
      ]
    }
  ]
}